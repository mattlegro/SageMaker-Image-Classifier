{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c7edf4-e926-4a57-ae7b-279773058984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = Session()\n",
    "\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14fd3d5a-fe21-402d-90b0-67f8ecd08bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e6517-4186-4b10-9034-a931470f3bf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7e1c9-29c1-4454-aa0a-78a9fff4ed7f",
   "metadata": {},
   "source": [
    "First, uploaded images to S3 from local storage. Then, we used the Data Wrangler to create an Image Resize Job to resize all images to the appropriate size for ResNet 50, (3,224,224). Next, we will turn the dataset into a recordIO, so that we can use the image classification algorithm. This step relies on the `preprocess.py` file found in the scripts folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7e7ca4-d5a2-4e63-acce-f1df118f8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3://lets-id-fish/fish-images-resized/Image-Resize-2023-09-14T13-41-28/image_col/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60ad400-620f-4d4c-986c-c985a58063b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.mxnet import MXNetProcessor\n",
    "# from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# mxp = MXNetProcessor(\n",
    "#     framework_version='1.8.0',\n",
    "#     py_version='py37',\n",
    "#     role=role, \n",
    "#     instance_count=1,\n",
    "#     instance_type='ml.t3.medium',\n",
    "#     base_job_name='frameworkprocessor-mxnet'\n",
    "# )\n",
    "\n",
    "# BUCKET = 'lets-id-fish'\n",
    "# S3_INPUT_PATH = 'fish-images-resized/Image-Resize-2023-09-14T13-41-28/image_col'\n",
    "\n",
    "\n",
    "# processing_inputs = [\n",
    "#     ProcessingInput(\n",
    "#         input_name=\"input_img_data_train\", \n",
    "#         source=f's3://{BUCKET}/{S3_INPUT_PATH}/train/',\n",
    "#         destination=\"/opt/ml/processing/input/data/\"\n",
    "#     ),\n",
    "#     ProcessingInput(\n",
    "#         input_name=\"input_img_data_val\", \n",
    "#         source=f's3://{BUCKET}/{S3_INPUT_PATH}/val/',\n",
    "#         destination=\"/opt/ml/processing/input/data/\"\n",
    "#     ),\n",
    "#     ProcessingInput(\n",
    "#         input_name=\"input_img_data_test\", \n",
    "#         source=f's3://{BUCKET}/{S3_INPUT_PATH}/test/',\n",
    "#         destination=\"/opt/ml/processing/input/data/\"\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# processing_outputs = [\n",
    "#     ProcessingOutput(\n",
    "#         output_name=\"train\", \n",
    "#         source=\"/opt/ml/processing/train\",\n",
    "#         destination=f\"s3://{BUCKET}/{S3_INPUT_PATH}/recordIO/train\"\n",
    "#     ),\n",
    "#     ProcessingOutput(\n",
    "#         output_name=\"validation\", \n",
    "#         source=\"/opt/ml/processing/validation\",\n",
    "#         destination=f\"s3://{BUCKET}/{S3_INPUT_PATH}/recordIO/validation\"\n",
    "#     ),\n",
    "#     ProcessingOutput(\n",
    "#         output_name=\"test\", \n",
    "#         source=\"/opt/ml/processing/test\",\n",
    "#         destination=f\"s3://{BUCKET}/{S3_INPUT_PATH}/recordIO/test\"\n",
    "#     )\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195eecc2-8ba3-449b-bf75-1efe77fc5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mxp.run(\n",
    "#     code=\"./scripts/preprocess.py\",\n",
    "#     inputs=processing_inputs,\n",
    "#     outputs=processing_outputs,\n",
    "#     arguments=[\n",
    "#         \"--input-s3-bucket\", \n",
    "#         input_data.default_value,\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e675a8c-f671-4cb6-8bef-5330b7222623",
   "metadata": {},
   "source": [
    "Actually, just going to use the image files for now, but saving this for later!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dce321-3069-40ae-a03f-af0998b97bdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fine-tune a pre-trained model on a custom dataset\n",
    "***\n",
    "The model available for fine-tuning attaches a classification layer to the corresponding feature extractor model available on TensorFlow/PyTorch hub, and initializes the layer parameters to random values. The output dimension of the classification layer\n",
    "is determined based on the number of classes in the input data. The fine-tuning step fine-tunes the model parameters. The objective is to minimize classification error on the input data. The model returned by fine-tuning can be further deployed for inference. Below are the instructions for how the training data should be formatted for input to the model. \n",
    "\n",
    "- **Input:** A directory with as many sub-directories as the number of classes. \n",
    "    - Each sub-directory should have images belonging to that class in .jpg format. \n",
    "- **Output:** A trained model that can be deployed for inference. \n",
    "    - A label mapping file is saved along with the trained model file on the s3 bucket.  \n",
    "    \n",
    "The input directory should look like below if \n",
    "the training data contains images from two classes: roses and dandelion. The s3 path should look like\n",
    "`s3://bucket_name/input_directory/`. Note the trailing `/` is required. The names of the folders and 'roses', 'dandelion', and the .jpg filenames\n",
    "can be anything. The label mapping file that is saved along with the trained model on the s3 bucket maps the \n",
    "folder names 'roses' and 'dandelion' to the indices in the list of class probabilities the model outputs.\n",
    "The mapping follows alphabetical ordering of the folder names. In the example below, index 0 in the model output list\n",
    "would correspond to 'dandelion' and index 1 would correspond to 'roses'.\n",
    "\n",
    "    input_directory\n",
    "        |--roses\n",
    "            |--abc.jpg\n",
    "            |--def.jpg\n",
    "        |--dandelion\n",
    "            |--ghi.jpg\n",
    "            |--jkl.jpg\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efab477-0ed1-422a-a40d-6e487a6b9e24",
   "metadata": {},
   "source": [
    "### Retrieve Training artifacts\n",
    "***\n",
    "Here, for the selected model, we retrieve the training docker container, the training algorithm source, the pre-trained base model, and a python dictionary of the training hyper-parameters that the algorithm accepts with their default values. Note that the model_version=\"*\" fetches the lates model. Also, we do need to specify the training_instance_type to fetch train_image_uri.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e523a2a-cbaf-428d-846b-e2b69f9b2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "\n",
    "model_id, model_version = \"pytorch-ic-resnet50\", \"*\"\n",
    "training_instance_type = \"ml.p3.2xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef73c9a0-60ed-436e-a655-9dcb7581d729",
   "metadata": {},
   "source": [
    "### Set Training parameters\n",
    "***\n",
    "Now that we are done with all the setup that is needed, we are ready to fine-tune our Image Classification model. To begin, let us create a [``sageMaker.estimator.Estimator``](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) object. This estimator will launch the training job. \n",
    "\n",
    "There are two kinds of parameters that need to be set for training. \n",
    "\n",
    "The first one are the parameters for the training job. These include: (i) Training data path. This is S3 folder in which the input data is stored, (ii) Output path: This the s3 folder in which the training output is stored. (iii) Training instance type: This indicates the type of machine on which to run the training. Typically, we use GPU instances for these training. We defined the training instance type above to fetch the correct train_image_uri. \n",
    "\n",
    "The second set of parameters are algorithm specific training hyper-parameters.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22afc8f-e6d6-4cd1-8b49-205adcc53d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3://lets-id-fish/fish-images-resized/Image-Resize-2023-09-14T13-41-28/image_col/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85d5baf2-c42d-4de2-a553-2665ad2d6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "data_bucket = \"lets-id-fish\"\n",
    "training_data_prefix = \"SpeciesID-Images\"\n",
    "\n",
    "training_dataset_s3_path = f\"s3://{data_bucket}/{training_data_prefix}/\"\n",
    "\n",
    "output_prefix = \"Models\"\n",
    "\n",
    "s3_output_location = f\"s3://{data_bucket}/{output_prefix}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75657d47-c94e-4b54-b05a-f7384c46b270",
   "metadata": {},
   "source": [
    "***\n",
    "For algorithm specific hyper-parameters, we start by fetching python dictionary of the training hyper-parameters that the algorithm accepts with their default values. This can then be overridden to custom values.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9123d1c0-0c5b-4560-a87b-3da0d4e73943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_only_top_layer': 'True', 'epochs': '5', 'learning_rate': '0.001', 'batch_size': '4', 'reinitialize_top_layer': 'Auto'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparam = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "print(hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0172a0-47cb-4ee3-aa64-f72cd4c31387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_only_top_layer': 'True', 'epochs': '5', 'learning_rate': '0.001', 'batch_size': '4', 'reinitialize_top_layer': 'Auto'}\n"
     ]
    }
   ],
   "source": [
    "hyperparam['epochs'] = '5'\n",
    "print(hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1b1f0ff-d6b4-42ea-927c-aba2f1a0da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam.update({'batch_size': '8'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "704fe1bb-1f84-4738-9b98-25de0383847b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters.validate_hyperparameters(hyperparameters=hyperparam,model_id=model_id, \n",
    "#                                          model_version=model_version, sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5df582-984e-49ea-ab3a-4f4d5d5d97cb",
   "metadata": {},
   "source": [
    "### Train with Automatic Model Tuning ([HPO](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)) <a id='AMT'></a>\n",
    "***\n",
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. We will use a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) object to interact with Amazon SageMaker hyperparameter tuning APIs.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc5a725f-75b0-4da9-86c5-deb5c2d1ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter\n",
    "\n",
    "# Use AMT for tuning and selecting the best model\n",
    "use_amt = True\n",
    "\n",
    "# Define objective metric per framework, based on which the best model will be selected.\n",
    "metric_definitions_per_model = {\n",
    "    \"tensorflow\": {\n",
    "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Maximize\",\n",
    "    },\n",
    "    \"pytorch\": {\n",
    "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val Acc: ([0-9\\\\.]+)\"},\n",
    "                   {\"Name\": \"val_loss\", \"Regex\": \"val Loss: ([0-9\\\\.]+)\"},\n",
    "                   {\"Name\": \"train_accuracy\", \"Regex\": \"train Acc: ([0-9\\\\.]+)\"},\n",
    "                   {\"Name\": \"train_loss\", \"Regex\": \"train Loss: ([0-9\\\\.]+)\"}],\n",
    "        \"type\": \"Maximize\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# You can select from the hyperparameters supported by the model, and configure ranges of values to be searched for training the optimal model.(https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)\n",
    "hyperparameter_ranges = {\n",
    "    \"adam-learning-rate\": ContinuousParameter(0.0001, 0.1, scaling_type=\"Logarithmic\")\n",
    "}\n",
    "\n",
    "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
    "max_jobs = 6\n",
    "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
    "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
    "max_parallel_jobs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa36a7d-3820-4548-947e-42e56e6c5520",
   "metadata": {},
   "source": [
    "### Start Training\n",
    "***\n",
    "We start by creating the estimator object with all the required assets and then launch the training job.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd76669d-219e-47f2-b698-8384465d4b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "training_job_name = name_from_base(f\"fish-id-{model_id}-transfer-learning\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "ic_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparam,\n",
    "    output_path=s3_output_location,\n",
    "    base_job_name=training_job_name,\n",
    "    enable_sagemaker_metrics=True\n",
    ")\n",
    "\n",
    "if use_amt:\n",
    "    metric_definitions = next(\n",
    "        value for key, value in metric_definitions_per_model.items() if model_id.startswith(key)\n",
    "    )\n",
    "\n",
    "    hp_tuner = HyperparameterTuner(\n",
    "        ic_estimator,\n",
    "        metric_definitions[\"metrics\"][0][\"Name\"],\n",
    "        hyperparameter_ranges,\n",
    "        metric_definitions[\"metrics\"],\n",
    "        max_jobs=max_jobs,\n",
    "        max_parallel_jobs=max_parallel_jobs,\n",
    "        objective_type=metric_definitions[\"type\"],\n",
    "        base_tuning_job_name=training_job_name,\n",
    "    )\n",
    "\n",
    "    # Launch a SageMaker Tuning job to search for the best hyperparameters\n",
    "    hp_tuner.fit({\"training\": training_dataset_s3_path})\n",
    "else:\n",
    "    # Launch a SageMaker Training job by passing s3 path of the training data\n",
    "    ic_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c07b04e6-aea4-4536-b608-70c2e432cdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>val_accuracy</td>\n",
       "      <td>0.24660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>val_accuracy</td>\n",
       "      <td>0.42810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180.0</td>\n",
       "      <td>val_accuracy</td>\n",
       "      <td>0.46660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>val_accuracy</td>\n",
       "      <td>0.45550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360.0</td>\n",
       "      <td>val_accuracy</td>\n",
       "      <td>0.46661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>3.70890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>120.0</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>2.67290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180.0</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>2.64330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300.0</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>2.60580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>360.0</td>\n",
       "      <td>val_loss</td>\n",
       "      <td>2.64720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp   metric_name    value\n",
       "0        0.0  val_accuracy  0.24660\n",
       "1      120.0  val_accuracy  0.42810\n",
       "2      180.0  val_accuracy  0.46660\n",
       "3      300.0  val_accuracy  0.45550\n",
       "4      360.0  val_accuracy  0.46661\n",
       "5        0.0      val_loss  3.70890\n",
       "6      120.0      val_loss  2.67290\n",
       "7      180.0      val_loss  2.64330\n",
       "8      300.0      val_loss  2.60580\n",
       "9      360.0      val_loss  2.64720"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker import TrainingJobAnalytics\n",
    "\n",
    "if use_amt:  # If using amt, select the model for the best training job.\n",
    "    sage_client = boto3.Session().client(\"sagemaker\")\n",
    "    tuning_job_result = sage_client.describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=hp_tuner._current_job_name\n",
    "    )\n",
    "    last_training_job_name = tuning_job_result[\"BestTrainingJob\"][\"TrainingJobName\"]\n",
    "else:\n",
    "    last_training_job_name = ic_estimator._current_job_name\n",
    "    \n",
    "# Captured metrics can be accessed as a Pandas dataframe\n",
    "df = TrainingJobAnalytics(training_job_name=last_training_job_name).dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113bd45-41fa-4e80-97e4-9b9e50c4debf",
   "metadata": {},
   "source": [
    "## Incrementally train the fine-tuned model\n",
    "\n",
    "***\n",
    "Incremental training allows you to train a new model using an expanded dataset that contains an underlying pattern that was not accounted for in the previous training and which resulted in poor model performance. You can use the artifacts from an existing model and use an expanded dataset to train a new model. Incremental training saves both time and resources as you don’t need to retrain a model from scratch.\n",
    "\n",
    "One may use any dataset (old or new) as long as the dataset format remain the same (set of classes). Incremental training step is similar to the finetuning step discussed above with the following difference: In fine-tuning above, we start with a pre-trained model whereas in incremental training, we start with an existing fine-tuned model.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acade36d-8810-4aca-adb5-2265da0c4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the previously trained model path based on the output location where artifacts are stored previously and the training job name.\n",
    "\n",
    "if use_amt:  # If using amt, select the model for the best training job.\n",
    "    sage_client = boto3.Session().client(\"sagemaker\")\n",
    "    tuning_job_result = sage_client.describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=hp_tuner._current_job_name\n",
    "    )\n",
    "    last_training_job_name = tuning_job_result[\"BestTrainingJob\"][\"TrainingJobName\"]\n",
    "else:\n",
    "    last_training_job_name = ic_estimator._current_job_name\n",
    "\n",
    "\n",
    "last_trained_model_path = f\"{s3_output_location}/{last_training_job_name}/output/model.tar.gz\"\n",
    "\n",
    "# last_trained_model_path = 's3://lets-id-fish/Models/fish-id-pytorch-ic-r-230911-2229-001-d615bcdd/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dc19023-7369-4ca3-a017-8b6ff1e3c5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparam.update({'epochs': '20'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f0dfb63-747d-4823-b671-3436c9700a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: fish-id-pytorch-ic-resnet50-incremental-2023-10-03-16-42-59-835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-03 16:42:59 Starting - Starting the training job......\n",
      "2023-10-03 16:43:34 Starting - Preparing the instances for training......\n",
      "2023-10-03 16:44:47 Downloading - Downloading input data......\n",
      "2023-10-03 16:45:52 Training - Downloading the training image.....................\n",
      "2023-10-03 16:49:23 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-03 16:49:47,477 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-03 16:49:47,506 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-03 16:49:47,510 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-03 16:49:47,804 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": \"8\",\n",
      "        \"epochs\": \"20\",\n",
      "        \"learning_rate\": \"0.001\",\n",
      "        \"reinitialize_top_layer\": \"Auto\",\n",
      "        \"train_only_top_layer\": \"True\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"fish-id-pytorch-ic-resnet50-incremental-2023-10-03-16-42-59-835\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/pytorch/transfer_learning/ic/v2.2.4/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":\"8\",\"epochs\":\"20\",\"learning_rate\":\"0.001\",\"reinitialize_top_layer\":\"Auto\",\"train_only_top_layer\":\"True\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/pytorch/transfer_learning/ic/v2.2.4/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":\"8\",\"epochs\":\"20\",\"learning_rate\":\"0.001\",\"reinitialize_top_layer\":\"Auto\",\"train_only_top_layer\":\"True\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"fish-id-pytorch-ic-resnet50-incremental-2023-10-03-16-42-59-835\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/pytorch/transfer_learning/ic/v2.2.4/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"8\",\"--epochs\",\"20\",\"--learning_rate\",\"0.001\",\"--reinitialize_top_layer\",\"Auto\",\"--train_only_top_layer\",\"True\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_REINITIALIZE_TOP_LAYER=Auto\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_ONLY_TOP_LAYER=True\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 transfer_learning.py --batch_size 8 --epochs 20 --learning_rate 0.001 --reinitialize_top_layer Auto --train_only_top_layer True\u001b[0m\n",
      "\u001b[34mdataset sizes: {'train': 36793, 'val': 9198}\u001b[0m\n",
      "\u001b[34mprediction class indices mapping to input training data labels: {'Ablennes_hians_': 0, 'Abudefduf_saxatilis_': 1, 'Abudefduf_taurus_': 2, 'Acanthemblemaria_aspera_': 3, 'Acanthemblemaria_maria_': 4, 'Acanthemblemaria_spinosa_': 5, 'Acanthostracion_polygonius_': 6, 'Acanthostracion_quadricornis_': 7, 'Acanthurus_chirurgus_': 8, 'Acanthurus_coeruleus_': 9, 'Acanthurus_tractus_': 10, 'Aetobatus_narinari_': 11, 'Albula_vulpes_': 12, 'Aluterus_scriptus_': 13, 'Amblycirrhitus_pinos_': 14, 'Amphelikturus_dendriticus_': 15, 'Anisotremus_surinamensis_': 16, 'Anisotremus_virginicus_': 17, 'Apogon_binotatus_': 18, 'Apogon_lachneri_': 19, 'Apogon_maculatus_': 20, 'Apogon_planifrons_': 21, 'Apogon_pseudomaculatus_': 22, 'Apogon_robinsi_': 23, 'Apogon_townsendi_': 24, 'Archosargus_probatocephalus_': 25, 'Astrapogon_puncticulatus_': 26, 'Aulostomus_maculatus_': 27, 'Balistes_vetula_': 28, 'Batrachoides_gilberti_': 29, 'Bodianus_pulchellus_': 30, 'Bodianus_rufus_': 31, 'Bothus_lunatus_': 32, 'Bothus_ocellatus_': 33, 'Brachygenys_chrysargyreum_': 34, 'Calamus_bajonado_': 35, 'Calamus_calamus_': 36, 'Calamus_pennatula_': 37, 'Callionymus_bairdi_': 38, 'Cantherhines_macrocerus_': 39, 'Cantherhines_pullus_': 40, 'Canthigaster_rostrata_': 41, 'Carcharhinus_perezii_': 42, 'Caretta_caretta_': 43, 'Centropyge_argi_': 44, 'Cephalopholis_cruentata_': 45, 'Cephalopholis_fulva_': 46, 'Chaetodipterus_faber_': 47, 'Chaetodon_capistratus_': 48, 'Chaetodon_ocellatus_': 49, 'Chaetodon_sedentarius_': 50, 'Chaetodon_striatus_': 51, 'Chelonia_mydas_': 52, 'Chilomycterus_antennatus_': 53, 'Chilomycterus_antillarum_': 54, 'Chilomycterus_reticulatus_': 55, 'Chromis_cyanea_': 56, 'Chromis_enchrysura_': 57, 'Chromis_insolata_': 58, 'Chromis_multilineata_': 59, 'Clepticus_parrae_': 60, 'Coryphopterus_dicrus_': 61, 'Coryphopterus_eidolon_': 62, 'Coryphopterus_glaucofraenum_': 63, 'Coryphopterus_hyalinus_': 64, 'Coryphopterus_lipernes_': 65, 'Coryphopterus_personatus_': 66, 'Coryphopterus_tortugae_': 67, 'Coryphopterus_venezuelae_': 68, 'Dactylopterus_volitans_': 69, 'Dasyatis_americana_': 70, 'Diodon_holocanthus_': 71, 'Diodon_hystrix_': 72, 'Diplectrum_bivittatum_': 73, 'Diplectrum_formosum_': 74, 'Diplodus_holbrookii_': 75, 'Echeneis_naucrates_': 76, 'Echeneis_neucratoides_': 77, 'Echidna_catenata_': 78, 'Elacatinus_cayman_': 79, 'Elacatinus_evelynae_': 80, 'Elacatinus_genie_': 81, 'Elacatinus_horsti_': 82, 'Elacatinus_illecebrosus_': 83, 'Elacatinus_lobeli_': 84, 'Elacatinus_lori_': 85, 'Elacatinus_louisae_': 86, 'Elacatinus_randalli_': 87, 'Enchelycore_carychroa_': 88, 'Enchelycore_nigricans_': 89, 'Enneanectes_atrorus_': 90, 'Eostichopus_arnesoni_': 91, 'Epinephelus_guttatus_': 92, 'Epinephelus_itajara_': 93, 'Epinephelus_striatus_': 94, 'Equetus_lanceolatus_': 95, 'Equetus_punctatus_': 96, 'Fistularia_tabacaria_': 97, 'Gerres_cinereus_': 98, 'Ginglymostoma_cirratum_': 99, 'Gobioclinus_filamentosus_': 100, 'Gramma_loreto_': 101, 'Gramma_melacara_': 102, 'Gymnothorax_funebris_': 103, 'Gymnothorax_miliaris_': 104, 'Gymnothorax_moringa_': 105, 'Gymnothorax_vicinus_': 106, 'Haemulon_vittatum_': 107, 'Halichoeres_bivittatus_': 108, 'Halichoeres_cyanocephalus_': 109, 'Halichoeres_garnoti_': 110, 'Halichoeres_maculipinna_': 111, 'Halichoeres_pictus_': 112, 'Halichoeres_poeyi_': 113, 'Halichoeres_radiatus_': 114, 'Hemiramphus_brasiliensis_': 115, 'Heteropriacanthus_cruentatus_': 116, 'Hippocampus_erectus_': 117, 'Hippocampus_reidi_': 118, 'Holacanthus_bermudensis_': 119, 'Holacanthus_ciliaris_': 120, 'Holacanthus_tricolor_': 121, 'Holothuria_floridana_': 122, 'Holothuria_mexicana_': 123, 'Holothuria_thomasi_': 124, 'Hypoplectrus_aberrans_': 125, 'Hypoplectrus_chlorurus_': 126, 'Hypoplectrus_gemma_': 127, 'Hypoplectrus_guttavarius_': 128, 'Hypoplectrus_indigo_': 129, 'Hypoplectrus_nigricans_': 130, 'Hypoplectrus_puella_': 131, 'Hypoplectrus_randallorum_': 132, 'Hypoplectrus_unicolor_': 133, 'Isostichopus_badionotus_': 134, 'Kyphosus_cinerascens_': 135, 'Kyphosus_sectatrix_': 136, 'Kyphosus_vaigiensis_': 137, 'Lactophrys_bicaudalis_': 138, 'Lactophrys_trigonus_': 139, 'Lactophrys_triqueter_': 140, 'Liopropoma_carmabi_': 141, 'Liopropoma_rubre_': 142, 'Malacanthus_plumieri_': 143, 'Manta_birostris_': 144, 'Megalops_atlanticus_': 145, 'Micrognathus_crinitus_': 146, 'Microspathodon_chrysurus_': 147, 'Monacanthus_ciliatus_': 148, 'Monacanthus_tuckeri_': 149, 'Mulloidichthys_martinicus_': 150, 'Mycteroperca_bonaci_': 151, 'Mycteroperca_interstitialis_': 152, 'Mycteroperca_tigris_': 153, 'Mycteroperca_venenosa_': 154, 'Myrichthys_breviceps_': 155, 'Myrichthys_ocellatus_': 156, 'Narcine_brasiliensis_': 157, 'Octopus_vulgaris_': 158, 'Ogcocephalus_nasutus_': 159, 'Ophichthus_ophis_': 160, 'Paranthias_furcifer_': 161, 'Pareques_acuminatus_': 162, 'Pareques_umbrosus_': 163, 'Pempheris_schomburgkii_': 164, 'Pomacanthus_arcuatus_': 165, 'Pomacanthus_paru_': 166, 'Priacanthus_arenatus_': 167, 'Pseudothyone_belli_': 168, 'Pterois_volitans_': 169, 'Rhincodon_typus_': 170, 'Rypticus_bistrispinus_': 171, 'Rypticus_saponaceus_': 172, 'Rypticus_subbifrenatus_': 173, 'Scomberomorus_regalis_': 174, 'Scorpaena_albifimbria_': 175, 'Scorpaena_grandicornis_': 176, 'Scorpaena_inermis_': 177, 'Scorpaena_plumieri_': 178, 'Scorpaenodes_caribbaeus_': 179, 'Serranus_subligarius_': 180, 'Serranus_tabacarius_': 181, 'Serranus_tigrinus_': 182, 'Serranus_tortugarum_': 183, 'Sphoeroides_spengleri_': 184, 'Sphoeroides_testudineus_': 185, 'Sphyraena_barracuda_': 186, 'Synodus_intermedius_': 187, 'Synodus_saurus_': 188, 'Trichechus_manatus_': 189, 'Urobatis_jamaicensis_': 190}\u001b[0m\n",
      "\u001b[34mEpoch 0/19\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.035 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.080 algo-1:27 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.080 algo-1:27 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.081 algo-1:27 INFO hook.py:200] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.082 algo-1:27 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.082 algo-1:27 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.350 algo-1:27 INFO hook.py:591] name:fc.weight count_params:477184\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.350 algo-1:27 INFO hook.py:591] name:fc.bias count_params:233\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.350 algo-1:27 INFO hook.py:593] Total Trainable Params: 477417\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.351 algo-1:27 INFO hook.py:424] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-10-03 16:49:53.355 algo-1:27 INFO hook.py:488] Hook is writing from the hook with pid: 27\u001b[0m\n",
      "\u001b[34mtrain Loss: 3.2383 train Acc: 0.3193\u001b[0m\n",
      "\u001b[34mval Loss: 2.3272 val Acc: 0.4796\u001b[0m\n",
      "\u001b[34mEpoch 1/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.7982 train Acc: 0.5589\u001b[0m\n",
      "\u001b[34mval Loss: 1.5655 val Acc: 0.6173\u001b[0m\n",
      "\u001b[34mEpoch 2/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6767 train Acc: 0.5929\u001b[0m\n",
      "\u001b[34mval Loss: 1.4973 val Acc: 0.6357\u001b[0m\n",
      "\u001b[34mEpoch 3/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6558 train Acc: 0.5930\u001b[0m\n",
      "\u001b[34mval Loss: 1.4919 val Acc: 0.6377\u001b[0m\n",
      "\u001b[34mEpoch 4/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6513 train Acc: 0.5976\u001b[0m\n",
      "\u001b[34mval Loss: 1.5369 val Acc: 0.6237\u001b[0m\n",
      "\u001b[34mEpoch 5/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6385 train Acc: 0.6011\u001b[0m\n",
      "\u001b[34mval Loss: 1.4960 val Acc: 0.6321\u001b[0m\n",
      "\u001b[34mEpoch 6/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6296 train Acc: 0.5998\u001b[0m\n",
      "\u001b[34mval Loss: 1.4789 val Acc: 0.6347\u001b[0m\n",
      "\u001b[34mEpoch 7/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6463 train Acc: 0.5960\u001b[0m\n",
      "\u001b[34mval Loss: 1.4675 val Acc: 0.6380\u001b[0m\n",
      "\u001b[34mEpoch 8/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6542 train Acc: 0.5919\u001b[0m\n",
      "\u001b[34mval Loss: 1.4947 val Acc: 0.6327\u001b[0m\n",
      "\u001b[34mEpoch 9/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6565 train Acc: 0.5974\u001b[0m\n",
      "\u001b[34mval Loss: 1.4834 val Acc: 0.6335\u001b[0m\n",
      "\u001b[34mEpoch 10/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6484 train Acc: 0.5964\u001b[0m\n",
      "\u001b[34mval Loss: 1.5079 val Acc: 0.6265\u001b[0m\n",
      "\u001b[34mEpoch 11/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6582 train Acc: 0.5944\u001b[0m\n",
      "\u001b[34mval Loss: 1.5188 val Acc: 0.6299\u001b[0m\n",
      "\u001b[34mEpoch 12/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6416 train Acc: 0.5973\u001b[0m\n",
      "\u001b[34mval Loss: 1.5084 val Acc: 0.6300\u001b[0m\n",
      "\u001b[34mEpoch 13/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6534 train Acc: 0.5980\u001b[0m\n",
      "\u001b[34mval Loss: 1.5327 val Acc: 0.6220\u001b[0m\n",
      "\u001b[34mEpoch 14/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6588 train Acc: 0.5945\u001b[0m\n",
      "\u001b[34mval Loss: 1.5873 val Acc: 0.6136\u001b[0m\n",
      "\u001b[34mEpoch 15/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6637 train Acc: 0.5953\u001b[0m\n",
      "\u001b[34mval Loss: 1.5126 val Acc: 0.6347\u001b[0m\n",
      "\u001b[34mEpoch 16/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6433 train Acc: 0.5974\u001b[0m\n",
      "\u001b[34mval Loss: 1.4871 val Acc: 0.6311\u001b[0m\n",
      "\u001b[34mEpoch 17/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6487 train Acc: 0.5964\u001b[0m\n",
      "\u001b[34mval Loss: 1.5565 val Acc: 0.6187\u001b[0m\n",
      "\u001b[34mEpoch 18/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6515 train Acc: 0.5973\u001b[0m\n",
      "\u001b[34mval Loss: 1.5244 val Acc: 0.6304\u001b[0m\n",
      "\u001b[34mEpoch 19/19\u001b[0m\n",
      "\u001b[34mtrain Loss: 1.6454 train Acc: 0.5991\u001b[0m\n",
      "\u001b[34mval Loss: 1.5170 val Acc: 0.6272\u001b[0m\n",
      "\u001b[34mTraining complete in 49m 18s\u001b[0m\n",
      "\u001b[34mBest val Acc: 0.637965\u001b[0m\n",
      "\u001b[34m2023-10-03 17:39:11,335 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-10-03 17:39:32 Uploading - Uploading generated training model\n",
      "2023-10-03 17:39:32 Completed - Training job completed\n",
      "Training seconds: 3285\n",
      "Billable seconds: 3285\n"
     ]
    }
   ],
   "source": [
    "incremental_training_job_name = name_from_base(f\"fish-id-{model_id}-incremental-training\")\n",
    "augmented_dataset_prefix = \"species-id-images-augmented\"\n",
    "augmented_data_path = f\"s3://{data_bucket}/{augmented_dataset_prefix}/\"\n",
    "\n",
    "incremental_train_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=last_trained_model_path,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparam,\n",
    "    output_path=s3_output_location,\n",
    "    base_job_name=incremental_training_job_name,\n",
    "    enable_sagemaker_metrics=True\n",
    ")\n",
    "\n",
    "incremental_train_estimator.fit({\"training\": augmented_data_path}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9efe6-adb6-47a4-84f8-bb2ef33ede2d",
   "metadata": {},
   "source": [
    "Once trained, we can use the same steps as in [Deploy & run Inference on the fine-tuned model](#4.5.-Deploy-&-run-Inference-on-the-fine-tuned-model) to deploy the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c32500-0d0c-4913-8375-3916f0df4391",
   "metadata": {},
   "source": [
    "## Deploy & run Inference on the fine-tuned model\n",
    "***\n",
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, that means predicting the class label of an image. We follow the same steps as in [3. Run inference on the pre-trained model](#3.-Run-inference-on-the-pre-trained-model). We start by retrieving the artifacts for deploying an endpoint. However, instead of base_predictor, we  deploy the `ic_estimator` that we fine-tuned.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b1fb9f-1fc5-4ecb-b40a-b061d5aafc94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::928680607065:role/SageMakerExecution'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aws_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f897c2b9-3311-4a19-84fe-5712516948e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "\n",
    "model_id, model_version = \"pytorch-ic-resnet50\", \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a86f66b-d4e6-4090-b5bc-26ce3477ac25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "model_url = \"s3://lets-id-fish/Models/fish-id-pytorch-ic-resnet50-incremental-2023-10-03-16-42-59-835/output/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa22032-092b-493f-86f5-de05761f06a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "inference_instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"fishid-endpoint-{model_id}-\")\n",
    "\n",
    "model = Model(image_uri=deploy_image_uri, \n",
    "              model_data=model_url, \n",
    "              role=aws_role)\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "finetuned_predictor = model.deploy(\n",
    "    \n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "802656f6-dc29-4fc5-96db-1e4df0aec221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.model.Model object at 0x7f731e9e7d30>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9a8f2-885e-4acb-aee6-b51d734ef5e6",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we download example images of a rose and a sunflower from the S3 bucket for inference.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbaf275-0ab9-487a-b5e5-94cd8ece6539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s3://lets-id-fish/SpeciesID-Images-ForAWS-ByCommonFamily/test/Angelfishes/3852_287.jpg\n",
    "# s3://lets-id-fish/SpeciesID-Images-ForAWS-ByCommonFamily/test/Wrasses/3889_8215.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0329cb2-8343-49b7-bbe2-4fcd3a5bb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"lets-id-fish\"\n",
    "key_prefix = \"SpeciesID-Images\"\n",
    "\n",
    "\n",
    "def download_from_s3(images):\n",
    "    for filename, image_key in images.items():\n",
    "        boto3.client(\"s3\").download_file(s3_bucket, f\"{key_prefix}/{image_key}\", filename)\n",
    "\n",
    "\n",
    "fish_images = {\n",
    "    \"4242_626.jpg\": \"Acanthurus_chirurgus_/4242_626.jpg\",\n",
    "    \"harlequinbass13.jpg\": \"Serranus_tigrinus_/harlequinbass13.jpg\",\n",
    "}\n",
    "download_from_s3(fish_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd95fb-bdf9-4c09-8300-9e5701b7f8e0",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we query the fine-tuned model, parse the response and display the predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00975aa6-d859-478b-81ff-e3abbb4fe908",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from model with message \"Your invocation timed out while waiting for a response from container model. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/fishid-endpoint-pytorch-ic-resnet50--2023-10-04-17-45-37-804 in account 928680607065 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(image_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 10\u001b[0m query_response \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContentType\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/x-image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAccept\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json;verbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# query_response = finetuned_predictor.predict(\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     img, {\"ContentType\": \"application/x-image\", \"Accept\": \"application/json;verbose\"}\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model_predictions \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(query_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/base_predictor.py:185\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the inference from the specified endpoint.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m        as is.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m request_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_request_args(\n\u001b[1;32m    178\u001b[0m     data,\n\u001b[1;32m    179\u001b[0m     initial_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     custom_attributes,\n\u001b[1;32m    184\u001b[0m )\n\u001b[0;32m--> 185\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:980\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    978\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    979\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from model with message \"Your invocation timed out while waiting for a response from container model. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/fishid-endpoint-pytorch-ic-resnet50--2023-10-04-17-45-37-804 in account 928680607065 for more information."
     ]
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "\n",
    "predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name,sagemaker_session=sess)\n",
    "predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "\n",
    "for image_filename in fish_images.keys():\n",
    "    with open(image_filename, \"rb\") as file:\n",
    "        img = file.read()\n",
    "    query_response = predictor.predict(\n",
    "        img, {\"ContentType\": \"application/x-image\", \"Accept\": \"application/json;verbose\"}\n",
    "    )\n",
    "    # query_response = finetuned_predictor.predict(\n",
    "    #     img, {\"ContentType\": \"application/x-image\", \"Accept\": \"application/json;verbose\"}\n",
    "    # )\n",
    "    model_predictions = json.loads(query_response)\n",
    "    predicted_label = model_predictions[\"predicted_label\"]\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<img src={image_filename} alt={image_filename} align=\"left\" style=\"width: 250px;\"/>'\n",
    "            f\"<figcaption>Predicted Label: {predicted_label}</figcaption>\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441cf4d-ec06-459a-b97c-042121e42e4e",
   "metadata": {},
   "source": [
    "Sick! Inference is working!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46daebb-2097-41fa-b390-ca1c40f0b892",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we clean up the deployed endpoint.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e3c4d3e-6150-42eb-a760-0348d322fd35",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'delete_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Delete the SageMaker endpoint and the attached resources\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfinetuned_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_model\u001b[49m()\n\u001b[1;32m      3\u001b[0m finetuned_predictor\u001b[38;5;241m.\u001b[39mdelete_endpoint()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'delete_model'"
     ]
    }
   ],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "finetuned_predictor.delete_model()\n",
    "finetuned_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d05721f-168d-4672-86e8-3a34485dd69d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
